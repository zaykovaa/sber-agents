# Техническое видение проекта: Telegram Bot - Эксперт кино

## Технологии

### Обязательный стек
- **Python 3.10+** — основной язык разработки, используем async/await для асинхронной работы
- **uv** — современный менеджер зависимостей (быстрая и надежная альтернатива pip)
- **aiogram 3.x** — фреймворк для работы с Telegram Bot API, polling для получения обновлений
- **openai** — клиент для работы с LLM через OpenRouter API (совместим с GPT-3.5, GPT-4 и другими моделями)
- **python-dotenv** — загрузка конфигурации из .env файла
- **Make** — автоматизация рутинных команд (setup, run, clean)

### Принцип выбора технологий
- Минимум зависимостей для простоты поддержки
- Актуальные и популярные библиотеки с хорошей документацией
- Следование принципам KISS и YAGNI

## Принципы разработки

### KISS (Keep It Simple, Stupid)
- Простая архитектура: один класс бота, минимум абстракций
- Нет лишних слоев, middleware, handlers для финальной версии
- Прямолинейный код, который легко читать и понимать

### YAGNI (You Aren't Gonna Need It)
- Реализуем только то, что нужно для работы MVP
- Не создаем обобщенные решения "на будущее"
- Отказываемся от преждевременной оптимизации

### Практические следствия
- **Один файл** для основной логики (`src/bot.py`)
- **Отдельная история диалога** для каждого пользователя (dict в памяти)
- **Простой polling** вместо webhook (меньше сложности)
- **Никаких баз данных** пока не нужно
- **Минимальная обработка ошибок**: логирование и продолжение работы

## Структура проекта

```
03-aidd/
├── src/                    # Исходный код
│   ├── __init__.py        # Пустой init файл
│   └── bot.py             # Единственный файл с логикой бота
├── docs/                   # Документация проекта
│   └── vision.md          # Техническое видение (этот документ)
├── .env                    # Конфигурация и секреты (не в git)
├── .gitignore              # Игнорируемые файлы
├── Makefile                # Команды для разработки
├── pyproject.toml          # Зависимости и настройки проекта (uv)
├── README.md               # Документация для пользователей
└── uv.lock                 # Закрепленные версии зависимостей
```

### Принципы организации
- **Минимум файлов**: только необходимое
- **Все в src/bot.py**: логика бота в одном месте
- **Make для автоматизации**: стандартные команды через make
- **Документация в docs**: техническое видение отдельно от пользовательской документации

## Архитектура проекта

### Общий подход
Одна класс-обертка `FilmExpertBot`, которая содержит всю логику бота и взаимодействует с внешними API.

### Компоненты
1. **FilmExpertBot** — главный класс со всей логикой
2. **OpenAI Client** — клиент для работы с LLM через OpenRouter
3. **aiogram Bot** — Telegram бот с polling
4. **Conversation Storage** — история диалогов в памяти (dict)

### Поток данных
```
Пользователь → Telegram → aiogram Handler → FilmExpertBot
                                                  ↓
                                          История диалога
                                                  ↓
                                          OpenAI Client → OpenRouter → LLM
                                                  ↓
                                          Ответ обратно пользователю
```

### Ключевые методы класса
- `__init__()` — загрузка конфигурации, инициализация клиентов
- `start_handler()` — обработчик команды /start
- `help_handler()` — обработчик команды /help
- `clear_handler()` — обработчик команды /clear
- `message_handler()` — обработчик текстовых сообщений
- `generate_response()` — генерация ответа через LLM
- `run()` — запуск бота с polling

### Особенности архитектуры
- **Нет слоев абстракции**: все в одном классе
- **In-memory storage**: история в RAM, теряется при перезапуске
- **Простой polling**: один процесс, без webhook
- **Async/await**: полностью асинхронный код для эффективности

## Модель данных

### История диалога
```python
conversations: Dict[int, List[Dict[str, str]]]
```
- **Ключ**: `user_id` (int) — ID пользователя в Telegram
- **Значение**: список сообщений в формате OpenAI Chat API

### Формат сообщения
```python
{
    "role": "system" | "user" | "assistant",
    "content": "текст сообщения"
}
```

### Структура истории для одного пользователя
```python
[
    {"role": "system", "content": "Ты — профессиональный эксперт..."},
    {"role": "user", "content": "Что посмотреть?"},
    {"role": "assistant", "content": "Рекомендую..."},
    {"role": "user", "content": "А что еще?"},
    # ... максимум 10 сообщений (настраивается)
]
```

### Системные данные
```python
stats: Dict[str, Any] = {
    "total_users": 0,      # Количество уникальных пользователей
    "total_messages": 0,   # Общее количество обработанных сообщений
    "start_time": "..."    # Время запуска бота
}
```

### Принципы хранения данных
- **Нет БД**: все в памяти, максимально просто
- **Автоматическая очистка**: при перезапуске бота история теряется
- **Ограничение длины**: максимум N сообщений в истории (по умолчанию 10)
- **Отдельная история**: для каждого пользователя своя история

## Работа с LLM

### Конфигурация
- **Провайдер**: OpenRouter API
- **Модель**: настраивается через `MODEL_NAME` (по умолчанию `openai/gpt-3.5-turbo`)
- **Клиент**: OpenAI Python SDK с кастомным `base_url`
- **API Key**: из переменной окружения `OPENROUTER_API_KEY`

### Системный промпт
Роль бота определяется системным промптом, который задается в начале каждой истории диалога:
```
Ты — профессиональный эксперт в области кино и сериалов...
```
Системный промпт описывает:
- Роль и задачи бота
- Стиль общения
- Особенности ответов
- Поведение в различных ситуациях

### Процесс генерации ответа
1. Получение сообщения от пользователя
2. Добавление в историю диалога (с системным промптом, если первый раз)
3. Отправка полной истории в LLM через OpenAI API
4. Получение ответа от LLM
5. Сохранение ответа в истории
6. Отправка ответа пользователю

### Параметры запроса к LLM
- **messages**: полная история диалога с системным промптом
- **model**: настраиваемая модель через конфиг
- **temperature**: не задается (используется дефолт)
- **max_tokens**: не задается (используется дефолт)

### Обработка ошибок
- При ошибке LLM возвращаем пользователю сообщение об ошибке
- Логируем ошибку для отладки
- Бот продолжает работу
- История диалога не повреждается

### Принципы работы
- **Всегда полная история**: отправляем весь контекст диалога
- **Простой формат**: используем стандартный Chat API без дополнительных параметров
- **Без сложной логики**: никаких пересказов, суммаризаций, проверок
- **Прямой прокидывание**: запрос → LLM → ответ

## Сценарии работы

### 1. Запуск бота
```
make setup  # Установка зависимостей
make run    # Запуск бота
```
- Бот инициализируется, загружает конфигурацию из `.env`
- Проверяет наличие необходимых ключей
- Запускает aiogram polling
- Готов к получению сообщений

### 2. Первое сообщение от пользователя (/start)
- Пользователь отправляет `/start`
- Бот инициализирует новую историю диалога для пользователя
- Добавляет системный промпт в начало истории
- Отправляет приветственное сообщение
- Обновляет статистику (total_users++)

### 3. Обычное текстовое сообщение
- Пользователь пишет вопрос о кино
- Бот получает сообщение через polling
- Добавляет сообщение пользователя в историю
- Отправляет полную историю в LLM
- Получает ответ от LLM
- Сохраняет ответ в историю
- Отправляет ответ пользователю
- Обновляет статистику (total_messages++)

### 4. Очистка истории (/clear)
- Пользователь отправляет `/clear`
- Бот создает новую пустую историю с системным промптом
- Уведомляет пользователя об очистке

### 5. Справка (/help)
- Пользователь отправляет `/help`
- Бот отправляет описание команд и возможностей

### 6. Обработка ошибок
- Если LLM недоступен: логируем ошибку, отправляем сообщение пользователю
- Если неверный конфиг: логируем и завершаем с ошибкой при старте
- Если пользователь не найден: создаем новую историю
- Бот всегда продолжает работать после ошибки обработки сообщения

### Принципы сценариев
- **Простые и прямые**: без сложной логики
- **Отдельная история**: каждый пользователь изолирован
- **Статистика**: минимальная, только для отслеживания использования
- **Без персистентности**: все в памяти, теряется при перезапуске

## Подход к конфигурированию

### Формат конфигурации
Все настройки хранятся в файле `.env` в корне проекта (не коммитится в git).
Используется библиотека `python-dotenv` для загрузки переменных окружения.

### Структура .env файла
```bash
# OpenRouter API Configuration
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
MODEL_NAME=openai/gpt-3.5-turbo

# Telegram Bot Configuration
TELEGRAM_BOT_TOKEN=1234567890:ABCdefGHIjklMNOpqrsTUVwxyz

# Bot Settings
MAX_HISTORY_MESSAGES=10
```

### Параметры конфигурации

#### Обязательные
- `OPENROUTER_API_KEY` — API ключ для доступа к OpenRouter (скрыт в .gitignore)
- `TELEGRAM_BOT_TOKEN` — токен бота от @BotFather (скрыт в .gitignore)

#### Опциональные с дефолтами
- `OPENROUTER_BASE_URL` — базовый URL для OpenRouter API (по умолчанию: `https://openrouter.ai/api/v1`)
- `MODEL_NAME` — модель LLM (по умолчанию: `openai/gpt-3.5-turbo`)
- `MAX_HISTORY_MESSAGES` — максимум сообщений в истории (по умолчанию: `10`)

### Загрузка конфигурации
```python
from dotenv import load_dotenv
import os

load_dotenv()  # Загружает переменные из .env

api_key = os.getenv("OPENROUTER_API_KEY")
base_url = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
```

### Проверка конфигурации
- При старте бота проверяются обязательные параметры
- Если отсутствует: логируем ошибку и завершаем программу
- Опциональные параметры используют дефолтные значения

### Принципы конфигурации
- **Простота**: все в одном файле .env
- **Без валидации**: проверяем только наличие обязательных параметров
- **Без преобразований**: минимальная обработка значений
- **Без секретов**: чувствительные данные храним в .env, не коммитим

## Подход к логгированию

### Используемая библиотека
Стандартная библиотека Python `logging` — без дополнительных зависимостей.

### Базовая конфигурация
```python
import logging

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)
```

### Формат логов
```
2024-01-01 12:00:00 - __main__ - INFO - Получено сообщение от 12345
```

### Уровни логирования
- **INFO** — основная информация о работе бота (сообщения, команды, статистика)
- **ERROR** — ошибки при работе (проблемы с LLM, некорректная конфигурация)

### Что логируем
- Запуск бота и инициализация
- Получение сообщений от пользователей (с ID пользователя)
- Отправка ответов пользователям
- Использование токенов LLM (при наличии)
- Ошибки при работе с LLM
- Ошибки конфигурации

### Где пишутся логи
- **stdout**: все логи выводятся в консоль
- **Без файлов**: не создаем файлы логов для простоты
- **Без ротации**: логи просто выводятся в консоль

### Принципы логгирования
- **Минимально**: только необходимая информация для отладки
- **Без персональных данных**: не логируем содержимое сообщений полностью
- **Без накопления**: не храним логи между перезапусками
- **Понятно**: человеку должно быть легко читать логи

