# Техническое видение проекта: Telegram Bot - Эксперт кино

## Технологии

### Обязательный стек
- **Python 3.10+** — основной язык разработки, используем async/await для асинхронной работы
- **uv** — современный менеджер зависимостей (быстрая и надежная альтернатива pip)
- **aiogram 3.x** — фреймворк для работы с Telegram Bot API, polling для получения обновлений
- **openai** — клиент для работы с LLM через OpenRouter API (совместим с GPT-3.5, GPT-4 и другими моделями)
- **python-dotenv** — загрузка конфигурации из .env файла
- **Make** — автоматизация рутинных команд (setup, run, clean)

### Принцип выбора технологий
- Минимум зависимостей для простоты поддержки
- Актуальные и популярные библиотеки с хорошей документацией
- Следование принципам KISS и YAGNI

## Принципы разработки

### KISS (Keep It Simple, Stupid)
- Простая архитектура: один класс бота, минимум абстракций
- Нет лишних слоев, middleware, handlers для финальной версии
- Прямолинейный код, который легко читать и понимать

### YAGNI (You Aren't Gonna Need It)
- Реализуем только то, что нужно для работы MVP
- Не создаем обобщенные решения "на будущее"
- Отказываемся от преждевременной оптимизации

### Практические следствия
- **Модульная структура** для организации кода (handlers, services, config, storage)
- **Отдельная история диалога** для каждого пользователя (dict в памяти)
- **Простой polling** вместо webhook (меньше сложности)
- **Никаких баз данных** пока не нужно
- **Системные промпты в файлах** для удобства редактирования
- **Минимальная обработка ошибок**: логирование и продолжение работы

## Структура проекта

```
04-multimodal/
├── src/                    # Исходный код
│   ├── __init__.py
│   ├── bot.py             # Главный файл запуска бота
│   ├── config.py          # Конфигурация (загрузка переменных окружения)
│   ├── storage.py         # Хранение истории диалогов
│   ├── handlers/          # Обработчики сообщений
│   │   ├── __init__.py
│   │   ├── commands.py    # Обработчики команд (/start, /help, /clear)
│   │   ├── text.py        # Обработчик текстовых сообщений
│   │   └── image.py       # Обработчик изображений
│   └── services/          # Сервисы для работы с внешними API
│       ├── __init__.py
│       ├── llm.py         # Сервис для работы с LLM через OpenRouter
│       └── image.py       # Сервис для обработки изображений
├── prompts/                # Системные промпты
│   ├── system_prompt_text.txt   # Промпт для текстовых сообщений
│   └── system_prompt_image.txt  # Промпт для обработки изображений
├── docs/                   # Документация проекта
│   ├── vision.md          # Техническое видение (этот документ)
│   ├── conventions.md     # Конвенции кода
│   ├── workflow.md        # Процесс разработки
│   └── tasklist.md        # Список задач
├── .env                    # Конфигурация и секреты (не в git)
├── .env.example            # Пример конфигурации
├── .gitignore              # Игнорируемые файлы
├── Makefile                # Команды для разработки
├── pyproject.toml          # Зависимости и настройки проекта (uv)
├── README.md               # Документация для пользователей
└── uv.lock                 # Закрепленные версии зависимостей
```

### Принципы организации
- **Модульная структура**: разделение на handlers, services, config, storage
- **Разделение ответственности**: каждый модуль отвечает за свою область
- **Промпты в файлах**: системные промпты хранятся в папке prompts для удобства редактирования
- **Make для автоматизации**: стандартные команды через make
- **Документация в docs**: техническое видение отдельно от пользовательской документации

## Архитектура проекта

### Общий подход
Модульная архитектура с разделением ответственности:
- **bot.py** — главный файл, инициализация и запуск бота
- **handlers/** — обработчики сообщений и команд
- **services/** — сервисы для работы с внешними API (LLM, изображения)
- **storage.py** — хранение истории диалогов
- **config.py** — конфигурация и загрузка промптов

### Компоненты
1. **FilmExpertBot** — главный класс, координирует работу всех компонентов
2. **CommandHandlers** — обработчики команд (/start, /help, /clear)
3. **TextHandler** — обработчик текстовых сообщений
4. **ImageHandler** — обработчик изображений
5. **LLMService** — сервис для работы с LLM через OpenRouter
6. **ImageService** — сервис для обработки изображений (загрузка, конвертация)
7. **ConversationStorage** — хранение истории диалогов в памяти
8. **Config** — загрузка конфигурации и системных промптов

### Поток данных
```
Пользователь → Telegram → aiogram Dispatcher
                              ↓
                    Handlers (commands/text/image)
                              ↓
                    Services (LLM/Image)
                              ↓
                    Storage (Conversation History)
                              ↓
                    LLMService → OpenRouter → LLM
                              ↓
                    Ответ обратно пользователю
```

### Структура обработки

#### Текстовое сообщение:
```
TextHandler → ConversationStorage → LLMService → OpenRouter → LLM
```

#### Изображение:
```
ImageHandler → ImageService (загрузка/конвертация) 
            → ConversationStorage (с vision промптом)
            → LLMService (vision модель) → OpenRouter → LLM
```

### Особенности архитектуры
- **Модульная структура**: разделение на handlers, services, storage, config
- **Разделение ответственности**: каждый модуль отвечает за свою область
- **In-memory storage**: история в RAM, теряется при перезапуске
- **Простой polling**: один процесс, без webhook
- **Async/await**: полностью асинхронный код для эффективности
- **Промпты в файлах**: системные промпты загружаются из папки prompts

## Модель данных

### История диалога
```python
conversations: Dict[int, List[Dict[str, str]]]
```
- **Ключ**: `user_id` (int) — ID пользователя в Telegram
- **Значение**: список сообщений в формате OpenAI Chat API

### Формат сообщения

#### Текстовое сообщение:
```python
{
    "role": "system" | "user" | "assistant",
    "content": "текст сообщения"
}
```

#### Мультимодальное сообщение (с изображением):
```python
{
    "role": "user",
    "content": [
        {
            "type": "text",
            "text": "описание изображения"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "data:image/jpeg;base64,..."
            }
        }
    ]
}
```

### Структура истории для одного пользователя
```python
[
    {"role": "system", "content": "Ты — профессиональный эксперт..."},
    {"role": "user", "content": "Что посмотреть?"},
    {"role": "assistant", "content": "Рекомендую..."},
    {"role": "user", "content": "А что еще?"},
    # ... максимум 10 сообщений (настраивается)
]
```

### Системные данные
```python
stats: Dict[str, Any] = {
    "total_users": 0,      # Количество уникальных пользователей
    "total_messages": 0,   # Общее количество обработанных сообщений
    "start_time": "..."    # Время запуска бота
}
```

### Принципы хранения данных
- **Нет БД**: все в памяти, максимально просто
- **Автоматическая очистка**: при перезапуске бота история теряется
- **Ограничение длины**: максимум N сообщений в истории (по умолчанию 10)
- **Отдельная история**: для каждого пользователя своя история

## Работа с LLM

### Конфигурация
- **Провайдер**: OpenRouter API
- **Модель**: настраивается через `MODEL_NAME` (по умолчанию `openai/gpt-3.5-turbo`)
- **Клиент**: OpenAI Python SDK с кастомным `base_url`
- **API Key**: из переменной окружения `OPENROUTER_API_KEY`

### Системные промпты
Роль бота определяется системными промптами, которые загружаются из файлов в папке `prompts/`:
- **system_prompt_text.txt** — промпт для текстовых сообщений
- **system_prompt_image.txt** — промпт для обработки изображений

Промпты загружаются при старте бота через `config.py` и могут быть переопределены через переменные окружения:
- `SYSTEM_PROMPT_TEXT` — переопределение текстового промпта
- `SYSTEM_PROMPT_IMAGE` — переопределение промпта для изображений
- `SYSTEM_PROMPT_TEXT_PATH` — путь к файлу с текстовым промптом
- `SYSTEM_PROMPT_IMAGE_PATH` — путь к файлу с промптом для изображений

Системный промпт описывает:
- Роль и задачи бота
- Стиль общения
- Особенности ответов
- Поведение в различных ситуациях
- Для изображений: инструкции по анализу и описанию

### Процесс генерации ответа

#### Для текстовых сообщений:
1. Получение текстового сообщения от пользователя
2. Добавление в историю диалога (с системным текстовым промптом, если первый раз)
3. Отправка полной истории в LLM через OpenAI API (текстовая модель)
4. Получение ответа от LLM
5. Сохранение ответа в истории
6. Отправка ответа пользователю

#### Для изображений:
1. Получение изображения от пользователя
2. Загрузка изображения через Telegram Bot API
3. Конвертация в base64 формат (data URL)
4. Формирование мультимодального сообщения (текст + изображение)
5. Добавление в историю диалога (с системным vision промптом, если первый раз)
6. Отправка полной истории в LLM через OpenAI API (vision модель)
7. Получение ответа от LLM
8. Сохранение ответа в истории
9. Отправка ответа пользователю

### Параметры запроса к LLM
- **messages**: полная история диалога с системным промптом
- **model**: настраиваемая модель через конфиг
  - Для текста: `MODEL_NAME` (по умолчанию `openai/gpt-3.5-turbo`)
  - Для изображений: `MODEL_IMAGE` (по умолчанию используется `MODEL_NAME`, но рекомендуется vision-модель)
- **temperature**: не задается (используется дефолт)
- **max_tokens**: не задается (используется дефолт)

### Обработка ошибок
- При ошибке LLM возвращаем пользователю сообщение об ошибке
- Логируем ошибку для отладки
- Бот продолжает работу
- История диалога не повреждается

### Принципы работы
- **Всегда полная история**: отправляем весь контекст диалога
- **Простой формат**: используем стандартный Chat API без дополнительных параметров
- **Без сложной логики**: никаких пересказов, суммаризаций, проверок
- **Прямой прокидывание**: запрос → LLM → ответ

## Сценарии работы

### 1. Запуск бота
```
make setup  # Установка зависимостей
make run    # Запуск бота
```
- Бот инициализируется, загружает конфигурацию из `.env`
- Проверяет наличие необходимых ключей
- Запускает aiogram polling
- Готов к получению сообщений

### 2. Первое сообщение от пользователя (/start)
- Пользователь отправляет `/start`
- Бот инициализирует новую историю диалога для пользователя
- Добавляет системный промпт в начало истории
- Отправляет приветственное сообщение
- Обновляет статистику (total_users++)

### 3. Обычное текстовое сообщение
- Пользователь пишет вопрос о кино
- Бот получает сообщение через polling
- TextHandler обрабатывает сообщение
- Добавляет сообщение пользователя в историю (с текстовым промптом)
- LLMService отправляет полную историю в LLM (текстовая модель)
- Получает ответ от LLM
- Сохраняет ответ в историю
- Отправляет ответ пользователю
- Обновляет статистику (total_messages++)

### 4. Обработка изображения
- Пользователь отправляет изображение (постер, скриншот)
- Бот получает изображение через polling
- ImageHandler обрабатывает изображение
- ImageService загружает изображение и конвертирует в base64
- Формирует мультимодальное сообщение (текст + изображение)
- Добавляет сообщение в историю (с vision промптом)
- LLMService отправляет полную историю в LLM (vision модель)
- Получает ответ от LLM
- Сохраняет ответ в историю
- Отправляет ответ пользователю
- Обновляет статистику (total_messages++)

### 5. Очистка истории (/clear)
- Пользователь отправляет `/clear`
- Бот создает новую пустую историю с системным промптом
- Уведомляет пользователя об очистке

### 6. Справка (/help)
- Пользователь отправляет `/help`
- Бот отправляет описание команд и возможностей

### 7. Обработка ошибок
- Если LLM недоступен: логируем ошибку, отправляем сообщение пользователю
- Если неверный конфиг: логируем и завершаем с ошибкой при старте
- Если пользователь не найден: создаем новую историю
- Бот всегда продолжает работать после ошибки обработки сообщения

### Принципы сценариев
- **Простые и прямые**: без сложной логики
- **Отдельная история**: каждый пользователь изолирован
- **Статистика**: минимальная, только для отслеживания использования
- **Без персистентности**: все в памяти, теряется при перезапуске

## Подход к конфигурированию

### Формат конфигурации
Все настройки хранятся в файле `.env` в корне проекта (не коммитится в git).
Используется библиотека `python-dotenv` для загрузки переменных окружения.

### Структура .env файла
```bash
# OpenRouter API Configuration
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
MODEL_NAME=openai/gpt-3.5-turbo

# Vision model for image processing (optional, defaults to MODEL_NAME)
MODEL_IMAGE=openai/gpt-4o-mini

# Telegram Bot Configuration
TELEGRAM_BOT_TOKEN=1234567890:ABCdefGHIjklMNOpqrsTUVwxyz

# Bot Settings
MAX_HISTORY_MESSAGES=10

# System Prompts (optional, defaults to prompts/ folder)
SYSTEM_PROMPT_TEXT_PATH=prompts/system_prompt_text.txt
SYSTEM_PROMPT_IMAGE_PATH=prompts/system_prompt_image.txt
# Или напрямую через переменные:
# SYSTEM_PROMPT_TEXT=твой промпт здесь
# SYSTEM_PROMPT_IMAGE=твой промпт для изображений
```

### Параметры конфигурации

#### Обязательные
- `OPENROUTER_API_KEY` — API ключ для доступа к OpenRouter (скрыт в .gitignore)
- `TELEGRAM_BOT_TOKEN` — токен бота от @BotFather (скрыт в .gitignore)

#### Опциональные с дефолтами
- `OPENROUTER_BASE_URL` — базовый URL для OpenRouter API (по умолчанию: `https://openrouter.ai/api/v1`)
- `MODEL_NAME` — модель LLM для текстовых сообщений (по умолчанию: `openai/gpt-3.5-turbo`)
- `MODEL_IMAGE` — модель LLM для обработки изображений (по умолчанию: `MODEL_NAME`)
- `MAX_HISTORY_MESSAGES` — максимум сообщений в истории (по умолчанию: `10`)
- `SYSTEM_PROMPT_TEXT_PATH` — путь к файлу с текстовым промптом (по умолчанию: `prompts/system_prompt_text.txt`)
- `SYSTEM_PROMPT_IMAGE_PATH` — путь к файлу с промптом для изображений (по умолчанию: `prompts/system_prompt_image.txt`)
- `SYSTEM_PROMPT_TEXT` — переопределение текстового промпта через переменную окружения
- `SYSTEM_PROMPT_IMAGE` — переопределение промпта для изображений через переменную окружения

### Загрузка конфигурации
```python
from dotenv import load_dotenv
import os

load_dotenv()  # Загружает переменные из .env

api_key = os.getenv("OPENROUTER_API_KEY")
base_url = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
```

### Проверка конфигурации
- При старте бота проверяются обязательные параметры
- Если отсутствует: логируем ошибку и завершаем программу
- Опциональные параметры используют дефолтные значения

### Принципы конфигурации
- **Простота**: все в одном файле .env
- **Без валидации**: проверяем только наличие обязательных параметров
- **Без преобразований**: минимальная обработка значений
- **Без секретов**: чувствительные данные храним в .env, не коммитим

## Подход к логгированию

### Используемая библиотека
Стандартная библиотека Python `logging` — без дополнительных зависимостей.

### Базовая конфигурация
```python
import logging

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)
```

### Формат логов
```
2024-01-01 12:00:00 - __main__ - INFO - Получено сообщение от 12345
```

### Уровни логирования
- **INFO** — основная информация о работе бота (сообщения, команды, статистика)
- **ERROR** — ошибки при работе (проблемы с LLM, некорректная конфигурация)

### Что логируем
- Запуск бота и инициализация
- Получение сообщений от пользователей (с ID пользователя)
- Отправка ответов пользователям
- Использование токенов LLM (при наличии)
- Ошибки при работе с LLM
- Ошибки конфигурации

### Где пишутся логи
- **stdout**: все логи выводятся в консоль
- **Без файлов**: не создаем файлы логов для простоты
- **Без ротации**: логи просто выводятся в консоль

### Принципы логгирования
- **Минимально**: только необходимая информация для отладки
- **Без персональных данных**: не логируем содержимое сообщений полностью
- **Без накопления**: не храним логи между перезапусками
- **Понятно**: человеку должно быть легко читать логи

