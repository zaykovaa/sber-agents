[project]
name = "telegram-llm-bot"
version = "0.1.0"
description = "Simple Telegram bot with LLM integration"
requires-python = ">=3.11,<3.12"
dependencies = [
    "aiogram>=3.15.0",
    "openai>=1.54.0",
    "python-dotenv>=1.0.0",
    "langchain>=0.3.0",
    "langchain-openai>=0.2.0",
    "langchain-community>=0.3.0",
    "langchain-core>=0.3.0",
    "langchain-text-splitters>=0.3.0",
    "langchain-huggingface>=0.1.0",
    "langchain-classic>=0.3.0",
    "pypdf>=5.0.0",
    "langsmith>=0.1.0",
    "jq>=1.0.0",
    "ragas>=0.2.0",
    "datasets>=3.0.0",
    # Pin to pre-3.0 for compatibility with torch 2.0.x on macOS x86_64
    "sentence-transformers>=2.2.0,<3.0.0",
    # Transformers flex_attention integration requires torch>=2.1; pin below that
    "transformers<4.42.0",
    "rank-bm25>=0.2.0",
    # Explicit torch pins per macOS architecture to ensure available wheels
    "torch>=2.3,<2.6; platform_system == 'Darwin' and platform_machine == 'arm64'",
    "torch==2.0.1; platform_system == 'Darwin' and platform_machine == 'x86_64'",
    "numpy<2",
]

[tool.uv]
environments = ["sys_platform == 'darwin' and platform_machine == 'x86_64' and python_version == '3.11'"]
