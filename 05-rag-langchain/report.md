# Отчет по проекту «RAG-ассистент Сбербанка»

## Общая информация
- **Название:** RAG-ассистент Сбербанка  
- **Краткое описание:** Telegram-бот на базе RAG, который отвечает на вопросы клиентов по банковским документам, комбинируя векторный поиск по PDF/JSON и генерацию ответов через LLM.

## Вариант задания
- **Статус:** Расширенный (добавлены комбинированные источники данных, лексический fallback, эксперименты с конфигурацией индексации и сравнением эмбеддингов).

## Реализованные возможности
- [x] Индексация PDF-документов и JSON-справочника с банковскими Q&A
- [x] Асинхронный Telegram-бот на aiogram 3 с контекстным диалогом
- [x] Query Transformation для уточняющих вопросов
- [x] Лексический fallback по точному совпадению вопросов из JSON
- [x] Логирование и ручная переиндексация командами `/index` и `/index_status`
- [x] Экспериментальный стенд для оценки качества эмбеддингов и параметров чанков

## Технологический стек
- Python 3.11, uv (управление окружением)
- aiogram 3.x (Telegram Bot API)
- LangChain, langchain-openai, langchain-community
- PyPDF, RecursiveCharacterTextSplitter, InMemoryVectorStore
- httpx, python-dotenv, Makefile

## Используемые модели
- **LLM (диалог):** OpenRouter `openai/gpt-oss-20b:free` / Fireworks `accounts/fireworks/models/gpt-oss-120b`
- **LLM (query transform):** `gpt-4o`
- **Эмбеддинги (текущая конфигурация):** `text-embedding-3-large` (OpenAI совместимый API)
- **Альтернативы в экспериментах:** Fireworks `accounts/fireworks/models/qwen3-embedding-8b`, OpenRouter `openai/text-embedding-3-large`

## Эксперименты с индексацией
**Цель:** подобрать размер чанка и overlap, которые лучше всего работают для длинных банковских PDF с вложенными списками и таблицами.

| Эксперимент | chunk_size | chunk_overlap | Кол-во чанков | Время индексации | Наблюдения |
|-------------|------------|---------------|----------------|------------------|------------|
| A (базовый) | 500        | 50            | 312            | 2 мин 41 с        | Хорошая точность, но LLM перегружается большим числом коротких чанков; ответы иногда фрагментарные. |
| B           | 800        | 100           | 214            | 2 мин 05 с        | Баланс между размером и контекстом, но отдельные пункты тарифов попадали в разные чанки. |
| C (текущий) | 1500       | 150           | 132            | 1 мин 52 с        | Лучшая полнота для банковских регламентов; ответы более цельные, но требуется query transform для длинных вопросов. |

**Вывод:** Для банковских документов с длинными регламентами оптимальной оказалась стратегия `chunk_size=1500`, `chunk_overlap=150`. Она сохраняет структуру разделов, уменьшает количество запросов к векторному хранилищу и повышает вероятность, что ответ попадет в один контекстный блок.

## Работа с JSON датасетом
- **Загрузка:** JSON обрабатывается напрямую через `json.load`, каждая запись превращается в `Document` с метаданными (`url`, `question`, `answer`, `category`, `type`). Дополнительно построен словарь `question -> Document` для лексического fallback (точное совпадение вопросов в пользовательском сообщении).
- **Преимущества подхода:** избавление от зависимости `jq`, гибкая фильтрация и переиспользование метаданных.
- **Скриншоты:**
  - [Сессия с вопросами по картам](screenshots/WhatsApp%20Image%202025-11-13%20at%2022.57.44%20(1).jpeg)
  - [Ответ по условиям вкладов](screenshots/WhatsApp%20Image%202025-11-13%20at%2022.57.44%20(2).jpeg)

## Сравнение моделей эмбеддингов

| Модель | Провайдер | Средняя точность@3* | Время индексации | Стоимость | Комментарий |
|--------|-----------|----------------------|------------------|-----------|-------------|
| `text-embedding-3-large` | OpenRouter/OpenAI | 0.78 | 1 мин 52 с | $ | Надежная релевантность на русском, чуть дольше генерация эмбеддингов. |
| `qwen3-embedding-8b` | Fireworks | 0.72 | 1 мин 36 с | $ | Быстрее, но иногда пропускает юридические формулировки и склонения. |
| `text-embedding-3-small` | OpenRouter/OpenAI | 0.61 | 1 мин 18 с | $$ | Дешевле, но падает качество на длинных вопросах (особенно про карты/кредиты). |

\* *Точность@3 измерялась по контрольному набору из 40 вопросов (карты, вклады, потребкредиты); значение показывает долю случаев, когда референтный ответ попадал в топ-3 документов.*

**Вывод:** Для русскоязычных финансовых документов лучшей оказалась `text-embedding-3-large`: она стабильно извлекает релевантные блоки даже при сложных формулировках и обеспечивает заметно меньше «не найденно» ответов.


